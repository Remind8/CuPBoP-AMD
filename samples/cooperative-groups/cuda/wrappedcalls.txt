; ModuleID = '/nethome/xzhou381/amdcuda/samples/cooperative-groups/cuda/main-cuda-nvptx64-nvidia-cuda-sm_35.bc.translated_test.bc'
source_filename = "main.cu"
target datalayout = "e-p:64:64-p1:64:64-p2:32:32-p3:32:32-p4:64:64-p5:32:32-p6:32:32-i64:64-v16:16-v24:32-v32:32-v48:64-v96:128-v192:256-v256:256-v512:512-v1024:1024-v2048:2048-n32:64-S32-A5-G1-ni:7"
target triple = "amdgcn-amd-amdhsa"

%struct.__cuda_builtin_blockIdx_t = type { i8 }
%struct.__cuda_builtin_blockDim_t = type { i8 }
%struct.__cuda_builtin_threadIdx_t = type { i8 }
%struct.__cuda_builtin_gridDim_t = type { i8 }
%"class.cooperative_groups::__v1::thread_group" = type { %union.anon }
%union.anon = type { %"struct.cooperative_groups::__v1::thread_group::tg_data" }
%"struct.cooperative_groups::__v1::thread_group::tg_data" = type { i64, i32, i32 }
%"class.cooperative_groups::__v1::thread_block" = type { %"struct.cooperative_groups::__v1::thread_group_base" }
%"struct.cooperative_groups::__v1::thread_group_base" = type { %"class.cooperative_groups::__v1::thread_group" }
%struct.int4 = type { i32, i32, i32, i32 }
%struct.dim3 = type { i32, i32, i32 }
%"struct.cooperative_groups::__v1::thread_group::gg_data" = type { ptr }
%"struct.cooperative_groups::__v1::details::grid_workspace" = type { i32, i32 }

$_ZNK18cooperative_groups4__v112thread_group11thread_rankEv = comdat any

$_ZNK18cooperative_groups4__v112thread_group4syncEv = comdat any

$_ZN18cooperative_groups4__v117this_thread_blockEv = comdat any

$_ZNK18cooperative_groups4__v112thread_group4sizeEv = comdat any

$_ZN25__cuda_builtin_blockIdx_t17__fetch_builtin_xEv = comdat any

$_ZN25__cuda_builtin_blockDim_t17__fetch_builtin_xEv = comdat any

$_ZN26__cuda_builtin_threadIdx_t17__fetch_builtin_xEv = comdat any

$_ZN24__cuda_builtin_gridDim_t17__fetch_builtin_xEv = comdat any

$_ZN18cooperative_groups4__v111thread_rankINS0_15coalesced_groupEEEDTcldtfp_11thread_rankEERKT_ = comdat any

$_ZN18cooperative_groups4__v111thread_rankINS0_12thread_blockEEEDTcldtfp_11thread_rankEERKT_ = comdat any

$_ZN18cooperative_groups4__v111thread_rankINS0_10grid_groupEEEDTcldtfp_11thread_rankEERKT_ = comdat any

$_ZNK18cooperative_groups4__v115coalesced_group11thread_rankEv = comdat any

$_ZN18cooperative_groups4__v112thread_block11thread_rankEv = comdat any

$_ZNK26__cuda_builtin_threadIdx_tcv4dim3Ev = comdat any

$_ZNK25__cuda_builtin_blockDim_tcv4dim3Ev = comdat any

$_ZN26__cuda_builtin_threadIdx_t17__fetch_builtin_yEv = comdat any

$_ZN26__cuda_builtin_threadIdx_t17__fetch_builtin_zEv = comdat any

$_ZN4dim3C1Ejjj = comdat any

$_ZN4dim3C2Ejjj = comdat any

$_ZN25__cuda_builtin_blockDim_t17__fetch_builtin_yEv = comdat any

$_ZN25__cuda_builtin_blockDim_t17__fetch_builtin_zEv = comdat any

$_ZNK18cooperative_groups4__v110grid_group11thread_rankEv = comdat any

$_ZNK25__cuda_builtin_blockIdx_tcv4dim3Ev = comdat any

$_ZNK24__cuda_builtin_gridDim_tcv4dim3Ev = comdat any

$_ZN25__cuda_builtin_blockIdx_t17__fetch_builtin_yEv = comdat any

$_ZN25__cuda_builtin_blockIdx_t17__fetch_builtin_zEv = comdat any

$_ZN24__cuda_builtin_gridDim_t17__fetch_builtin_yEv = comdat any

$_ZN24__cuda_builtin_gridDim_t17__fetch_builtin_zEv = comdat any

$_ZN18cooperative_groups4__v14syncINS0_15coalesced_groupEEEvRKT_ = comdat any

$_ZN18cooperative_groups4__v14syncINS0_12thread_blockEEEvRKT_ = comdat any

$_ZN18cooperative_groups4__v14syncINS0_10grid_groupEEEvRKT_ = comdat any

$_ZNK18cooperative_groups4__v115coalesced_group4syncEv = comdat any

$_Z10__syncwarpj = comdat any

$_ZN18cooperative_groups4__v112thread_block4syncEv = comdat any

$_Z14__barrier_syncj = comdat any

$_ZNK18cooperative_groups4__v110grid_group4syncEv = comdat any

$_ZNK18cooperative_groups4__v110grid_group8is_validEv = comdat any

$_ZN18cooperative_groups4__v112thread_blockC1Ev = comdat any

$_ZN18cooperative_groups4__v112thread_blockC2Ev = comdat any

$_ZN18cooperative_groups4__v117thread_group_baseILj4EEC2Ev = comdat any

$_ZN18cooperative_groups4__v112thread_groupC2Ej = comdat any

$_ZN18cooperative_groups4__v110group_sizeINS0_15coalesced_groupEEEDTcldtfp_4sizeEERKT_ = comdat any

$_ZN18cooperative_groups4__v110group_sizeINS0_12thread_blockEEEDTcldtfp_4sizeEERKT_ = comdat any

$_ZN18cooperative_groups4__v110group_sizeINS0_10grid_groupEEEDTcldtfp_4sizeEERKT_ = comdat any

$_ZNK18cooperative_groups4__v115coalesced_group4sizeEv = comdat any

$_ZN18cooperative_groups4__v112thread_block4sizeEv = comdat any

$_ZNK18cooperative_groups4__v110grid_group4sizeEv = comdat any

@blockIdx = extern_weak addrspace(1) global %struct.__cuda_builtin_blockIdx_t, align 1
@blockDim = extern_weak addrspace(1) global %struct.__cuda_builtin_blockDim_t, align 1
@threadIdx = extern_weak addrspace(1) global %struct.__cuda_builtin_threadIdx_t, align 1
@gridDim = extern_weak addrspace(1) global %struct.__cuda_builtin_gridDim_t, align 1
@temp = external hidden addrspace(3) global [0 x i32], align 4

; Function Attrs: convergent mustprogress noinline nounwind optnone
define noundef i32 @_Z7cg_rankN18cooperative_groups4__v112thread_groupE(ptr noundef byval(%"class.cooperative_groups::__v1::thread_group") align 8 %0) #0 {
  %2 = call noundef i64 @_ZNK18cooperative_groups4__v112thread_group11thread_rankEv(ptr noundef nonnull align 8 dereferenceable(16) %0) #12
  %3 = trunc i64 %2 to i32
  ret i32 %3
}

; Function Attrs: alwaysinline convergent mustprogress nounwind
define linkonce_odr noundef i64 @_ZNK18cooperative_groups4__v112thread_group11thread_rankEv(ptr noundef nonnull align 8 dereferenceable(16) %0) #1 comdat align 2 {
  %2 = alloca ptr, align 8, addrspace(5)
  %3 = addrspacecast ptr addrspace(5) %2 to ptr
  %4 = alloca i64, align 8, addrspace(5)
  %5 = addrspacecast ptr addrspace(5) %4 to ptr
  store ptr %0, ptr %3, align 8
  %6 = load ptr, ptr %3, align 8
  store i64 0, ptr %5, align 8
  %7 = getelementptr inbounds %"class.cooperative_groups::__v1::thread_group", ptr %6, i32 0, i32 0
  %8 = load i8, ptr %7, align 8
  %9 = lshr i8 %8, 1
  %10 = zext i8 %9 to i32
  switch i32 %10, label %19 [
    i32 1, label %11
    i32 4, label %14
    i32 3, label %17
  ]

11:                                               ; preds = %1
  %12 = call noundef i32 @_ZN18cooperative_groups4__v111thread_rankINS0_15coalesced_groupEEEDTcldtfp_11thread_rankEERKT_(ptr noundef nonnull align 8 dereferenceable(16) %6) #12
  %13 = zext i32 %12 to i64
  store i64 %13, ptr %5, align 8
  br label %20

14:                                               ; preds = %1
  %15 = call noundef i32 @_ZN18cooperative_groups4__v111thread_rankINS0_12thread_blockEEEDTcldtfp_11thread_rankEERKT_(ptr noundef nonnull align 8 dereferenceable(16) %6) #12
  %16 = zext i32 %15 to i64
  store i64 %16, ptr %5, align 8
  br label %20

17:                                               ; preds = %1
  %18 = call noundef i64 @_ZN18cooperative_groups4__v111thread_rankINS0_10grid_groupEEEDTcldtfp_11thread_rankEERKT_(ptr noundef nonnull align 8 dereferenceable(16) %6) #12
  store i64 %18, ptr %5, align 8
  br label %20

19:                                               ; preds = %1
  br label %20

20:                                               ; preds = %19, %17, %14, %11
  %21 = load i64, ptr %5, align 8
  ret i64 %21
}

; Function Attrs: convergent mustprogress noinline nounwind optnone
define void @_Z7cg_syncN18cooperative_groups4__v112thread_groupE(ptr noundef byval(%"class.cooperative_groups::__v1::thread_group") align 8 %0) #0 {
  call void @_ZNK18cooperative_groups4__v112thread_group4syncEv(ptr noundef nonnull align 8 dereferenceable(16) %0) #12
  ret void
}

; Function Attrs: alwaysinline convergent mustprogress nounwind
define linkonce_odr void @_ZNK18cooperative_groups4__v112thread_group4syncEv(ptr noundef nonnull align 8 dereferenceable(16) %0) #1 comdat align 2 {
  %2 = alloca ptr, align 8, addrspace(5)
  %3 = addrspacecast ptr addrspace(5) %2 to ptr
  store ptr %0, ptr %3, align 8
  %4 = load ptr, ptr %3, align 8
  %5 = getelementptr inbounds %"class.cooperative_groups::__v1::thread_group", ptr %4, i32 0, i32 0
  %6 = load i8, ptr %5, align 8
  %7 = lshr i8 %6, 1
  %8 = zext i8 %7 to i32
  switch i32 %8, label %12 [
    i32 1, label %9
    i32 4, label %10
    i32 3, label %11
  ]

9:                                                ; preds = %1
  call void @_ZN18cooperative_groups4__v14syncINS0_15coalesced_groupEEEvRKT_(ptr noundef nonnull align 8 dereferenceable(16) %4) #12
  br label %13

10:                                               ; preds = %1
  call void @_ZN18cooperative_groups4__v14syncINS0_12thread_blockEEEvRKT_(ptr noundef nonnull align 8 dereferenceable(16) %4) #12
  br label %13

11:                                               ; preds = %1
  call void @_ZN18cooperative_groups4__v14syncINS0_10grid_groupEEEvRKT_(ptr noundef nonnull align 8 dereferenceable(16) %4) #12
  br label %13

12:                                               ; preds = %1
  br label %13

13:                                               ; preds = %12, %11, %10, %9
  ret void
}

; Function Attrs: convergent mustprogress noinline nounwind optnone
define %"class.cooperative_groups::__v1::thread_group" @_Z20cg_this_thread_blockv() #0 {
  %1 = alloca %"class.cooperative_groups::__v1::thread_group", align 8, addrspace(5)
  %2 = addrspacecast ptr addrspace(5) %1 to ptr
  %3 = alloca %"class.cooperative_groups::__v1::thread_block", align 8, addrspace(5)
  %4 = addrspacecast ptr addrspace(5) %3 to ptr
  %5 = call %"class.cooperative_groups::__v1::thread_block" @_ZN18cooperative_groups4__v117this_thread_blockEv() #12
  %6 = getelementptr inbounds %"class.cooperative_groups::__v1::thread_block", ptr %4, i32 0, i32 0
  %7 = extractvalue %"class.cooperative_groups::__v1::thread_block" %5, 0
  store %"struct.cooperative_groups::__v1::thread_group_base" %7, ptr %6, align 8
  call void @llvm.memcpy.p0.p0.i64(ptr align 8 %2, ptr align 8 %4, i64 16, i1 false)
  %8 = load %"class.cooperative_groups::__v1::thread_group", ptr %2, align 8
  ret %"class.cooperative_groups::__v1::thread_group" %8
}

; Function Attrs: alwaysinline convergent mustprogress nounwind
define linkonce_odr %"class.cooperative_groups::__v1::thread_block" @_ZN18cooperative_groups4__v117this_thread_blockEv() #1 comdat {
  %1 = alloca %"class.cooperative_groups::__v1::thread_block", align 8, addrspace(5)
  %2 = addrspacecast ptr addrspace(5) %1 to ptr
  call void @_ZN18cooperative_groups4__v112thread_blockC1Ev(ptr noundef nonnull align 8 dereferenceable(16) %2) #12
  %3 = load %"class.cooperative_groups::__v1::thread_block", ptr %2, align 8
  ret %"class.cooperative_groups::__v1::thread_block" %3
}

; Function Attrs: argmemonly nocallback nofree nounwind willreturn
declare void @llvm.memcpy.p0.p0.i64(ptr noalias nocapture writeonly, ptr noalias nocapture readonly, i64, i1 immarg) #2

; Function Attrs: convergent mustprogress noinline nounwind optnone
define noundef i32 @_Z10reduce_sumN18cooperative_groups4__v112thread_groupEPii(ptr noundef byval(%"class.cooperative_groups::__v1::thread_group") align 8 %0, ptr noundef %1, i32 noundef %2) #0 {
  %4 = alloca ptr, align 8, addrspace(5)
  %5 = addrspacecast ptr addrspace(5) %4 to ptr
  %6 = alloca i32, align 4, addrspace(5)
  %7 = addrspacecast ptr addrspace(5) %6 to ptr
  %8 = alloca i32, align 4, addrspace(5)
  %9 = addrspacecast ptr addrspace(5) %8 to ptr
  %10 = alloca %"class.cooperative_groups::__v1::thread_group", align 8, addrspace(5)
  %11 = addrspacecast ptr addrspace(5) %10 to ptr
  %12 = alloca i32, align 4, addrspace(5)
  %13 = addrspacecast ptr addrspace(5) %12 to ptr
  %14 = alloca %"class.cooperative_groups::__v1::thread_group", align 8, addrspace(5)
  %15 = addrspacecast ptr addrspace(5) %14 to ptr
  %16 = alloca %"class.cooperative_groups::__v1::thread_group", align 8, addrspace(5)
  %17 = addrspacecast ptr addrspace(5) %16 to ptr
  store ptr %1, ptr %5, align 8
  store i32 %2, ptr %7, align 4
  call void @llvm.memcpy.p0.p0.i64(ptr align 8 %11, ptr align 8 %0, i64 16, i1 false)
  %18 = call noundef i32 @_Z7cg_rankN18cooperative_groups4__v112thread_groupE(ptr noundef byval(%"class.cooperative_groups::__v1::thread_group") align 8 %11) #12
  store i32 %18, ptr %9, align 4
  %19 = call noundef i64 @_ZNK18cooperative_groups4__v112thread_group4sizeEv(ptr noundef nonnull align 8 dereferenceable(16) %0) #12
  %20 = udiv i64 %19, 2
  %21 = trunc i64 %20 to i32
  store i32 %21, ptr %13, align 4
  br label %22

22:                                               ; preds = %45, %3
  %23 = load i32, ptr %13, align 4
  %24 = icmp sgt i32 %23, 0
  br i1 %24, label %25, label %48

25:                                               ; preds = %22
  %26 = load i32, ptr %7, align 4
  %27 = load ptr, ptr %5, align 8
  %28 = load i32, ptr %9, align 4
  %29 = sext i32 %28 to i64
  %30 = getelementptr inbounds i32, ptr %27, i64 %29
  store i32 %26, ptr %30, align 4
  call void @llvm.memcpy.p0.p0.i64(ptr align 8 %15, ptr align 8 %0, i64 16, i1 false)
  call void @_Z7cg_syncN18cooperative_groups4__v112thread_groupE(ptr noundef byval(%"class.cooperative_groups::__v1::thread_group") align 8 %15) #12
  %31 = load i32, ptr %9, align 4
  %32 = load i32, ptr %13, align 4
  %33 = icmp slt i32 %31, %32
  br i1 %33, label %34, label %44

34:                                               ; preds = %25
  %35 = load ptr, ptr %5, align 8
  %36 = load i32, ptr %9, align 4
  %37 = load i32, ptr %13, align 4
  %38 = add nsw i32 %36, %37
  %39 = sext i32 %38 to i64
  %40 = getelementptr inbounds i32, ptr %35, i64 %39
  %41 = load i32, ptr %40, align 4
  %42 = load i32, ptr %7, align 4
  %43 = add nsw i32 %42, %41
  store i32 %43, ptr %7, align 4
  br label %44

44:                                               ; preds = %34, %25
  call void @llvm.memcpy.p0.p0.i64(ptr align 8 %17, ptr align 8 %0, i64 16, i1 false)
  call void @_Z7cg_syncN18cooperative_groups4__v112thread_groupE(ptr noundef byval(%"class.cooperative_groups::__v1::thread_group") align 8 %17) #12
  br label %45

45:                                               ; preds = %44
  %46 = load i32, ptr %13, align 4
  %47 = sdiv i32 %46, 2
  store i32 %47, ptr %13, align 4
  br label %22, !llvm.loop !8

48:                                               ; preds = %22
  %49 = load i32, ptr %7, align 4
  ret i32 %49
}

; Function Attrs: alwaysinline convergent mustprogress nounwind
define linkonce_odr noundef i64 @_ZNK18cooperative_groups4__v112thread_group4sizeEv(ptr noundef nonnull align 8 dereferenceable(16) %0) #1 comdat align 2 {
  %2 = alloca ptr, align 8, addrspace(5)
  %3 = addrspacecast ptr addrspace(5) %2 to ptr
  %4 = alloca i64, align 8, addrspace(5)
  %5 = addrspacecast ptr addrspace(5) %4 to ptr
  store ptr %0, ptr %3, align 8
  %6 = load ptr, ptr %3, align 8
  store i64 0, ptr %5, align 8
  %7 = getelementptr inbounds %"class.cooperative_groups::__v1::thread_group", ptr %6, i32 0, i32 0
  %8 = load i8, ptr %7, align 8
  %9 = lshr i8 %8, 1
  %10 = zext i8 %9 to i32
  switch i32 %10, label %19 [
    i32 1, label %11
    i32 4, label %14
    i32 3, label %17
  ]

11:                                               ; preds = %1
  %12 = call noundef i32 @_ZN18cooperative_groups4__v110group_sizeINS0_15coalesced_groupEEEDTcldtfp_4sizeEERKT_(ptr noundef nonnull align 8 dereferenceable(16) %6) #12
  %13 = zext i32 %12 to i64
  store i64 %13, ptr %5, align 8
  br label %20

14:                                               ; preds = %1
  %15 = call noundef i32 @_ZN18cooperative_groups4__v110group_sizeINS0_12thread_blockEEEDTcldtfp_4sizeEERKT_(ptr noundef nonnull align 8 dereferenceable(16) %6) #12
  %16 = zext i32 %15 to i64
  store i64 %16, ptr %5, align 8
  br label %20

17:                                               ; preds = %1
  %18 = call noundef i64 @_ZN18cooperative_groups4__v110group_sizeINS0_10grid_groupEEEDTcldtfp_4sizeEERKT_(ptr noundef nonnull align 8 dereferenceable(16) %6) #12
  store i64 %18, ptr %5, align 8
  br label %20

19:                                               ; preds = %1
  br label %20

20:                                               ; preds = %19, %17, %14, %11
  %21 = load i64, ptr %5, align 8
  ret i64 %21
}

; Function Attrs: convergent mustprogress noinline nounwind optnone
define noundef i32 @_Z10thread_sumPii(ptr noundef %0, i32 noundef %1) #0 {
  %3 = alloca ptr, align 8, addrspace(5)
  %4 = addrspacecast ptr addrspace(5) %3 to ptr
  %5 = alloca i32, align 4, addrspace(5)
  %6 = addrspacecast ptr addrspace(5) %5 to ptr
  %7 = alloca i32, align 4, addrspace(5)
  %8 = addrspacecast ptr addrspace(5) %7 to ptr
  %9 = alloca i32, align 4, addrspace(5)
  %10 = addrspacecast ptr addrspace(5) %9 to ptr
  %11 = alloca %struct.int4, align 16, addrspace(5)
  %12 = addrspacecast ptr addrspace(5) %11 to ptr
  store ptr %0, ptr %4, align 8
  store i32 %1, ptr %6, align 4
  store i32 0, ptr %8, align 4
  %13 = call noundef i32 @_ZN25__cuda_builtin_blockIdx_t17__fetch_builtin_xEv() #12
  %14 = call noundef i32 @_ZN25__cuda_builtin_blockDim_t17__fetch_builtin_xEv() #12
  %15 = mul i32 %13, %14
  %16 = call noundef i32 @_ZN26__cuda_builtin_threadIdx_t17__fetch_builtin_xEv() #12
  %17 = add i32 %15, %16
  store i32 %17, ptr %10, align 4
  br label %18

18:                                               ; preds = %41, %2
  %19 = load i32, ptr %10, align 4
  %20 = load i32, ptr %6, align 4
  %21 = sdiv i32 %20, 4
  %22 = icmp slt i32 %19, %21
  br i1 %22, label %23, label %47

23:                                               ; preds = %18
  %24 = load ptr, ptr %4, align 8
  %25 = load i32, ptr %10, align 4
  %26 = sext i32 %25 to i64
  %27 = getelementptr inbounds %struct.int4, ptr %24, i64 %26
  call void @llvm.memcpy.p0.p0.i64(ptr align 16 %12, ptr align 16 %27, i64 16, i1 false)
  %28 = getelementptr inbounds %struct.int4, ptr %12, i32 0, i32 0
  %29 = load i32, ptr %28, align 16
  %30 = getelementptr inbounds %struct.int4, ptr %12, i32 0, i32 1
  %31 = load i32, ptr %30, align 4
  %32 = add nsw i32 %29, %31
  %33 = getelementptr inbounds %struct.int4, ptr %12, i32 0, i32 2
  %34 = load i32, ptr %33, align 8
  %35 = add nsw i32 %32, %34
  %36 = getelementptr inbounds %struct.int4, ptr %12, i32 0, i32 3
  %37 = load i32, ptr %36, align 4
  %38 = add nsw i32 %35, %37
  %39 = load i32, ptr %8, align 4
  %40 = add nsw i32 %39, %38
  store i32 %40, ptr %8, align 4
  br label %41

41:                                               ; preds = %23
  %42 = call noundef i32 @_ZN25__cuda_builtin_blockDim_t17__fetch_builtin_xEv() #12
  %43 = call noundef i32 @_ZN24__cuda_builtin_gridDim_t17__fetch_builtin_xEv() #12
  %44 = mul i32 %42, %43
  %45 = load i32, ptr %10, align 4
  %46 = add i32 %45, %44
  store i32 %46, ptr %10, align 4
  br label %18, !llvm.loop !10

47:                                               ; preds = %18
  %48 = load i32, ptr %8, align 4
  ret i32 %48
}

; Function Attrs: alwaysinline convergent mustprogress nounwind
define linkonce_odr noundef i32 @_ZN25__cuda_builtin_blockIdx_t17__fetch_builtin_xEv() #1 comdat align 2 {
  %1 = call i32 @llvm.amdgcn.workgroup.id.x()
  ret i32 %1
}

; Function Attrs: alwaysinline convergent mustprogress nounwind
define linkonce_odr noundef i32 @_ZN25__cuda_builtin_blockDim_t17__fetch_builtin_xEv() #1 comdat align 2 {
  %1 = call i32 @cudaamd.nvvm.read.ptx.sreg.ntid.x()
  ret i32 %1
}

; Function Attrs: alwaysinline convergent mustprogress nounwind
define linkonce_odr noundef i32 @_ZN26__cuda_builtin_threadIdx_t17__fetch_builtin_xEv() #1 comdat align 2 {
  %1 = call i32 @llvm.amdgcn.workitem.id.x()
  ret i32 %1
}

; Function Attrs: alwaysinline convergent mustprogress nounwind
define linkonce_odr noundef i32 @_ZN24__cuda_builtin_gridDim_t17__fetch_builtin_xEv() #1 comdat align 2 {
  %1 = call i32 @cudaamd.nvvm.read.ptx.sreg.nctaid.x()
  ret i32 %1
}

; Function Attrs: convergent mustprogress noinline norecurse nounwind optnone
define amdgpu_kernel void @_Z16sum_kernel_blockPiS_i(ptr addrspace(1) noundef %0, ptr addrspace(1) noundef %1, i32 noundef %2) #3 {
  %4 = alloca ptr, align 8, addrspace(5)
  %5 = addrspacecast ptr addrspace(5) %4 to ptr
  %6 = alloca ptr, align 8, addrspace(5)
  %7 = addrspacecast ptr addrspace(5) %6 to ptr
  %8 = alloca i32, align 4, addrspace(5)
  %9 = addrspacecast ptr addrspace(5) %8 to ptr
  %10 = alloca i32, align 4, addrspace(5)
  %11 = addrspacecast ptr addrspace(5) %10 to ptr
  %12 = alloca %"class.cooperative_groups::__v1::thread_group", align 8, addrspace(5)
  %13 = addrspacecast ptr addrspace(5) %12 to ptr
  %14 = alloca i32, align 4, addrspace(5)
  %15 = addrspacecast ptr addrspace(5) %14 to ptr
  %16 = alloca %"class.cooperative_groups::__v1::thread_group", align 8, addrspace(5)
  %17 = addrspacecast ptr addrspace(5) %16 to ptr
  %18 = alloca %"class.cooperative_groups::__v1::thread_group", align 8, addrspace(5)
  %19 = addrspacecast ptr addrspace(5) %18 to ptr
  %20 = addrspacecast ptr addrspace(1) %0 to ptr
  store ptr %20, ptr %5, align 8
  %21 = addrspacecast ptr addrspace(1) %1 to ptr
  store ptr %21, ptr %7, align 8
  store i32 %2, ptr %9, align 4
  %22 = load ptr, ptr %7, align 8
  %23 = load i32, ptr %9, align 4
  %24 = call noundef i32 @_Z10thread_sumPii(ptr noundef %22, i32 noundef %23) #12
  store i32 %24, ptr %11, align 4
  %25 = call %"class.cooperative_groups::__v1::thread_group" @_Z20cg_this_thread_blockv() #12
  %26 = getelementptr inbounds %"class.cooperative_groups::__v1::thread_group", ptr %13, i32 0, i32 0
  %27 = extractvalue %"class.cooperative_groups::__v1::thread_group" %25, 0
  store %union.anon %27, ptr %26, align 8
  call void @llvm.memcpy.p0.p0.i64(ptr align 8 %17, ptr align 8 %13, i64 16, i1 false)
  %28 = load i32, ptr %11, align 4
  %29 = call noundef i32 @_Z10reduce_sumN18cooperative_groups4__v112thread_groupEPii(ptr noundef byval(%"class.cooperative_groups::__v1::thread_group") align 8 %17, ptr noundef addrspacecast (ptr addrspace(3) @temp to ptr), i32 noundef %28) #12
  store i32 %29, ptr %15, align 4
  call void @llvm.memcpy.p0.p0.i64(ptr align 8 %19, ptr align 8 %13, i64 16, i1 false)
  %30 = call noundef i32 @_Z7cg_rankN18cooperative_groups4__v112thread_groupE(ptr noundef byval(%"class.cooperative_groups::__v1::thread_group") align 8 %19) #12
  %31 = icmp eq i32 %30, 0
  br i1 %31, label %32, label %36

32:                                               ; preds = %3
  %33 = load ptr, ptr %5, align 8
  %34 = load i32, ptr %15, align 4
  %35 = call noundef i32 @_Z9atomicAddPii(ptr noundef %33, i32 noundef %34) #12
  br label %36

36:                                               ; preds = %32, %3
  ret void
}

; Function Attrs: alwaysinline convergent mustprogress nounwind
define linkonce_odr noundef i32 @_ZN18cooperative_groups4__v111thread_rankINS0_15coalesced_groupEEEDTcldtfp_11thread_rankEERKT_(ptr noundef nonnull align 8 dereferenceable(16) %0) #1 comdat {
  %2 = alloca ptr, align 8, addrspace(5)
  %3 = addrspacecast ptr addrspace(5) %2 to ptr
  store ptr %0, ptr %3, align 8
  %4 = load ptr, ptr %3, align 8
  %5 = call noundef i32 @_ZNK18cooperative_groups4__v115coalesced_group11thread_rankEv(ptr noundef nonnull align 8 dereferenceable(16) %4) #12
  ret i32 %5
}

; Function Attrs: alwaysinline convergent mustprogress nounwind
define linkonce_odr noundef i32 @_ZN18cooperative_groups4__v111thread_rankINS0_12thread_blockEEEDTcldtfp_11thread_rankEERKT_(ptr noundef nonnull align 8 dereferenceable(16) %0) #1 comdat {
  %2 = alloca ptr, align 8, addrspace(5)
  %3 = addrspacecast ptr addrspace(5) %2 to ptr
  store ptr %0, ptr %3, align 8
  %4 = load ptr, ptr %3, align 8
  %5 = call noundef i32 @_ZN18cooperative_groups4__v112thread_block11thread_rankEv() #12
  ret i32 %5
}

; Function Attrs: alwaysinline convergent mustprogress nounwind
define linkonce_odr noundef i64 @_ZN18cooperative_groups4__v111thread_rankINS0_10grid_groupEEEDTcldtfp_11thread_rankEERKT_(ptr noundef nonnull align 8 dereferenceable(16) %0) #1 comdat {
  %2 = alloca ptr, align 8, addrspace(5)
  %3 = addrspacecast ptr addrspace(5) %2 to ptr
  store ptr %0, ptr %3, align 8
  %4 = load ptr, ptr %3, align 8
  %5 = call noundef i64 @_ZNK18cooperative_groups4__v110grid_group11thread_rankEv(ptr noundef nonnull align 8 dereferenceable(16) %4) #12
  ret i64 %5
}

; Function Attrs: alwaysinline convergent mustprogress nounwind
define linkonce_odr noundef i32 @_ZNK18cooperative_groups4__v115coalesced_group11thread_rankEv(ptr noundef nonnull align 8 dereferenceable(16) %0) #1 comdat align 2 {
  %2 = alloca ptr, align 8, addrspace(5)
  %3 = addrspacecast ptr addrspace(5) %2 to ptr
  store ptr %0, ptr %3, align 8
  %4 = load ptr, ptr %3, align 8
  %5 = getelementptr inbounds %"class.cooperative_groups::__v1::thread_group", ptr %4, i32 0, i32 0
  %6 = getelementptr inbounds %"struct.cooperative_groups::__v1::thread_group::tg_data", ptr %5, i32 0, i32 1
  %7 = load i32, ptr %6, align 8
  %8 = call noundef i32 @_ZN18cooperative_groups4__v17detailsL13lanemask32_ltEv() #12
  %9 = and i32 %7, %8
  %10 = call noundef i32 @_ZL6__popci(i32 noundef %9) #12
  ret i32 %10
}

; Function Attrs: alwaysinline convergent mustprogress nounwind
define internal noundef i32 @_ZL6__popci(i32 noundef %0) #1 {
  %2 = alloca i32, align 4, addrspace(5)
  %3 = addrspacecast ptr addrspace(5) %2 to ptr
  store i32 %0, ptr %3, align 4
  %4 = load i32, ptr %3, align 4
  %5 = call i32 @__nv_popc(i32 noundef %4) #12
  ret i32 %5
}

; Function Attrs: alwaysinline convergent mustprogress nounwind
define internal noundef i32 @_ZN18cooperative_groups4__v17detailsL13lanemask32_ltEv() #1 {
  %1 = alloca i32, align 4, addrspace(5)
  %2 = addrspacecast ptr addrspace(5) %1 to ptr
  %3 = call i32 asm sideeffect "mov.u32 $0, %lanemask_lt;", "=r"() #12, !srcloc !11
  store i32 %3, ptr %2, align 4
  %4 = load i32, ptr %2, align 4
  ret i32 %4
}

; Function Attrs: alwaysinline convergent mustprogress nounwind
define linkonce_odr noundef i32 @_ZN18cooperative_groups4__v112thread_block11thread_rankEv() #1 comdat align 2 {
  %1 = call noundef i32 @_ZN18cooperative_groups4__v17details3ctaL11thread_rankEv() #12
  ret i32 %1
}

; Function Attrs: alwaysinline convergent mustprogress nounwind
define internal noundef i32 @_ZN18cooperative_groups4__v17details3ctaL11thread_rankEv() #1 {
  %1 = alloca %struct.dim3, align 4, addrspace(5)
  %2 = addrspacecast ptr addrspace(5) %1 to ptr
  %3 = alloca %struct.dim3, align 4, addrspace(5)
  %4 = addrspacecast ptr addrspace(5) %3 to ptr
  %5 = call %struct.dim3 @_ZNK26__cuda_builtin_threadIdx_tcv4dim3Ev(ptr noundef nonnull align 1 dereferenceable(1) addrspacecast (ptr addrspace(1) @threadIdx to ptr)) #12
  %6 = getelementptr inbounds %struct.dim3, ptr %2, i32 0, i32 0
  %7 = extractvalue %struct.dim3 %5, 0
  store i32 %7, ptr %6, align 4
  %8 = getelementptr inbounds %struct.dim3, ptr %2, i32 0, i32 1
  %9 = extractvalue %struct.dim3 %5, 1
  store i32 %9, ptr %8, align 4
  %10 = getelementptr inbounds %struct.dim3, ptr %2, i32 0, i32 2
  %11 = extractvalue %struct.dim3 %5, 2
  store i32 %11, ptr %10, align 4
  %12 = call %struct.dim3 @_ZNK25__cuda_builtin_blockDim_tcv4dim3Ev(ptr noundef nonnull align 1 dereferenceable(1) addrspacecast (ptr addrspace(1) @blockDim to ptr)) #12
  %13 = getelementptr inbounds %struct.dim3, ptr %4, i32 0, i32 0
  %14 = extractvalue %struct.dim3 %12, 0
  store i32 %14, ptr %13, align 4
  %15 = getelementptr inbounds %struct.dim3, ptr %4, i32 0, i32 1
  %16 = extractvalue %struct.dim3 %12, 1
  store i32 %16, ptr %15, align 4
  %17 = getelementptr inbounds %struct.dim3, ptr %4, i32 0, i32 2
  %18 = extractvalue %struct.dim3 %12, 2
  store i32 %18, ptr %17, align 4
  %19 = call noundef i32 @_ZN18cooperative_groups4__v17detailsL14vec3_to_linearIjEET_4dim3S4_(ptr noundef byval(%struct.dim3) align 4 %2, ptr noundef byval(%struct.dim3) align 4 %4) #12
  ret i32 %19
}

; Function Attrs: alwaysinline convergent mustprogress nounwind
define internal noundef i32 @_ZN18cooperative_groups4__v17detailsL14vec3_to_linearIjEET_4dim3S4_(ptr noundef byval(%struct.dim3) align 4 %0, ptr noundef byval(%struct.dim3) align 4 %1) #1 {
  %3 = getelementptr inbounds %struct.dim3, ptr %0, i32 0, i32 2
  %4 = load i32, ptr %3, align 4
  %5 = getelementptr inbounds %struct.dim3, ptr %1, i32 0, i32 1
  %6 = load i32, ptr %5, align 4
  %7 = mul i32 %4, %6
  %8 = getelementptr inbounds %struct.dim3, ptr %1, i32 0, i32 0
  %9 = load i32, ptr %8, align 4
  %10 = mul i32 %7, %9
  %11 = getelementptr inbounds %struct.dim3, ptr %0, i32 0, i32 1
  %12 = load i32, ptr %11, align 4
  %13 = getelementptr inbounds %struct.dim3, ptr %1, i32 0, i32 0
  %14 = load i32, ptr %13, align 4
  %15 = mul i32 %12, %14
  %16 = add i32 %10, %15
  %17 = getelementptr inbounds %struct.dim3, ptr %0, i32 0, i32 0
  %18 = load i32, ptr %17, align 4
  %19 = add i32 %16, %18
  ret i32 %19
}

; Function Attrs: convergent mustprogress noinline nounwind optnone
define linkonce_odr %struct.dim3 @_ZNK26__cuda_builtin_threadIdx_tcv4dim3Ev(ptr noundef nonnull align 1 dereferenceable(1) %0) #0 comdat align 2 {
  %2 = alloca %struct.dim3, align 4, addrspace(5)
  %3 = addrspacecast ptr addrspace(5) %2 to ptr
  %4 = alloca ptr, align 8, addrspace(5)
  %5 = addrspacecast ptr addrspace(5) %4 to ptr
  store ptr %0, ptr %5, align 8
  %6 = load ptr, ptr %5, align 8
  %7 = call noundef i32 @_ZN26__cuda_builtin_threadIdx_t17__fetch_builtin_xEv() #12
  %8 = call noundef i32 @_ZN26__cuda_builtin_threadIdx_t17__fetch_builtin_yEv() #12
  %9 = call noundef i32 @_ZN26__cuda_builtin_threadIdx_t17__fetch_builtin_zEv() #12
  call void @_ZN4dim3C1Ejjj(ptr noundef nonnull align 4 dereferenceable(12) %3, i32 noundef %7, i32 noundef %8, i32 noundef %9) #12
  %10 = load %struct.dim3, ptr %3, align 4
  ret %struct.dim3 %10
}

; Function Attrs: convergent mustprogress noinline nounwind optnone
define linkonce_odr %struct.dim3 @_ZNK25__cuda_builtin_blockDim_tcv4dim3Ev(ptr noundef nonnull align 1 dereferenceable(1) %0) #0 comdat align 2 {
  %2 = alloca %struct.dim3, align 4, addrspace(5)
  %3 = addrspacecast ptr addrspace(5) %2 to ptr
  %4 = alloca ptr, align 8, addrspace(5)
  %5 = addrspacecast ptr addrspace(5) %4 to ptr
  store ptr %0, ptr %5, align 8
  %6 = load ptr, ptr %5, align 8
  %7 = call noundef i32 @_ZN25__cuda_builtin_blockDim_t17__fetch_builtin_xEv() #12
  %8 = call noundef i32 @_ZN25__cuda_builtin_blockDim_t17__fetch_builtin_yEv() #12
  %9 = call noundef i32 @_ZN25__cuda_builtin_blockDim_t17__fetch_builtin_zEv() #12
  call void @_ZN4dim3C1Ejjj(ptr noundef nonnull align 4 dereferenceable(12) %3, i32 noundef %7, i32 noundef %8, i32 noundef %9) #12
  %10 = load %struct.dim3, ptr %3, align 4
  ret %struct.dim3 %10
}

; Function Attrs: alwaysinline convergent mustprogress nounwind
define linkonce_odr noundef i32 @_ZN26__cuda_builtin_threadIdx_t17__fetch_builtin_yEv() #1 comdat align 2 {
  %1 = call i32 @llvm.amdgcn.workitem.id.y()
  ret i32 %1
}

; Function Attrs: alwaysinline convergent mustprogress nounwind
define linkonce_odr noundef i32 @_ZN26__cuda_builtin_threadIdx_t17__fetch_builtin_zEv() #1 comdat align 2 {
  %1 = call i32 @llvm.amdgcn.workitem.id.z()
  ret i32 %1
}

; Function Attrs: convergent noinline nounwind optnone
define linkonce_odr void @_ZN4dim3C1Ejjj(ptr noundef nonnull align 4 dereferenceable(12) %0, i32 noundef %1, i32 noundef %2, i32 noundef %3) unnamed_addr #4 comdat align 2 {
  %5 = alloca ptr, align 8, addrspace(5)
  %6 = addrspacecast ptr addrspace(5) %5 to ptr
  %7 = alloca i32, align 4, addrspace(5)
  %8 = addrspacecast ptr addrspace(5) %7 to ptr
  %9 = alloca i32, align 4, addrspace(5)
  %10 = addrspacecast ptr addrspace(5) %9 to ptr
  %11 = alloca i32, align 4, addrspace(5)
  %12 = addrspacecast ptr addrspace(5) %11 to ptr
  store ptr %0, ptr %6, align 8
  store i32 %1, ptr %8, align 4
  store i32 %2, ptr %10, align 4
  store i32 %3, ptr %12, align 4
  %13 = load ptr, ptr %6, align 8
  %14 = load i32, ptr %8, align 4
  %15 = load i32, ptr %10, align 4
  %16 = load i32, ptr %12, align 4
  call void @_ZN4dim3C2Ejjj(ptr noundef nonnull align 4 dereferenceable(12) %13, i32 noundef %14, i32 noundef %15, i32 noundef %16) #12
  ret void
}

; Function Attrs: nocallback nofree nosync nounwind readnone speculatable willreturn
declare i32 @llvm.nvvm.read.ptx.sreg.tid.y() #5

; Function Attrs: nocallback nofree nosync nounwind readnone speculatable willreturn
declare i32 @llvm.nvvm.read.ptx.sreg.tid.z() #5

; Function Attrs: convergent noinline nounwind optnone
define linkonce_odr void @_ZN4dim3C2Ejjj(ptr noundef nonnull align 4 dereferenceable(12) %0, i32 noundef %1, i32 noundef %2, i32 noundef %3) unnamed_addr #4 comdat align 2 {
  %5 = alloca ptr, align 8, addrspace(5)
  %6 = addrspacecast ptr addrspace(5) %5 to ptr
  %7 = alloca i32, align 4, addrspace(5)
  %8 = addrspacecast ptr addrspace(5) %7 to ptr
  %9 = alloca i32, align 4, addrspace(5)
  %10 = addrspacecast ptr addrspace(5) %9 to ptr
  %11 = alloca i32, align 4, addrspace(5)
  %12 = addrspacecast ptr addrspace(5) %11 to ptr
  store ptr %0, ptr %6, align 8
  store i32 %1, ptr %8, align 4
  store i32 %2, ptr %10, align 4
  store i32 %3, ptr %12, align 4
  %13 = load ptr, ptr %6, align 8
  %14 = getelementptr inbounds %struct.dim3, ptr %13, i32 0, i32 0
  %15 = load i32, ptr %8, align 4
  store i32 %15, ptr %14, align 4
  %16 = getelementptr inbounds %struct.dim3, ptr %13, i32 0, i32 1
  %17 = load i32, ptr %10, align 4
  store i32 %17, ptr %16, align 4
  %18 = getelementptr inbounds %struct.dim3, ptr %13, i32 0, i32 2
  %19 = load i32, ptr %12, align 4
  store i32 %19, ptr %18, align 4
  ret void
}

; Function Attrs: alwaysinline convergent mustprogress nounwind
define linkonce_odr noundef i32 @_ZN25__cuda_builtin_blockDim_t17__fetch_builtin_yEv() #1 comdat align 2 {
  %1 = call i32 @cudaamd.nvvm.read.ptx.sreg.ntid.y()
  ret i32 %1
}

; Function Attrs: alwaysinline convergent mustprogress nounwind
define linkonce_odr noundef i32 @_ZN25__cuda_builtin_blockDim_t17__fetch_builtin_zEv() #1 comdat align 2 {
  %1 = call i32 @cudaamd.nvvm.read.ptx.sreg.ntid.z()
  ret i32 %1
}

; Function Attrs: nocallback nofree nosync nounwind readnone speculatable willreturn
declare i32 @llvm.nvvm.read.ptx.sreg.ntid.y() #5

; Function Attrs: nocallback nofree nosync nounwind readnone speculatable willreturn
declare i32 @llvm.nvvm.read.ptx.sreg.ntid.z() #5

; Function Attrs: alwaysinline convergent mustprogress nounwind
define linkonce_odr noundef i64 @_ZNK18cooperative_groups4__v110grid_group11thread_rankEv(ptr noundef nonnull align 8 dereferenceable(16) %0) #1 comdat align 2 {
  %2 = alloca ptr, align 8, addrspace(5)
  %3 = addrspacecast ptr addrspace(5) %2 to ptr
  store ptr %0, ptr %3, align 8
  %4 = load ptr, ptr %3, align 8
  %5 = call noundef i64 @_ZN18cooperative_groups4__v17details4gridL11thread_rankEv() #12
  ret i64 %5
}

; Function Attrs: alwaysinline convergent mustprogress nounwind
define internal noundef i64 @_ZN18cooperative_groups4__v17details4gridL11thread_rankEv() #1 {
  %1 = alloca i64, align 8, addrspace(5)
  %2 = addrspacecast ptr addrspace(5) %1 to ptr
  %3 = alloca %struct.dim3, align 4, addrspace(5)
  %4 = addrspacecast ptr addrspace(5) %3 to ptr
  %5 = alloca %struct.dim3, align 4, addrspace(5)
  %6 = addrspacecast ptr addrspace(5) %5 to ptr
  %7 = alloca %struct.dim3, align 4, addrspace(5)
  %8 = addrspacecast ptr addrspace(5) %7 to ptr
  %9 = alloca %struct.dim3, align 4, addrspace(5)
  %10 = addrspacecast ptr addrspace(5) %9 to ptr
  %11 = call %struct.dim3 @_ZNK25__cuda_builtin_blockIdx_tcv4dim3Ev(ptr noundef nonnull align 1 dereferenceable(1) addrspacecast (ptr addrspace(1) @blockIdx to ptr)) #12
  %12 = getelementptr inbounds %struct.dim3, ptr %4, i32 0, i32 0
  %13 = extractvalue %struct.dim3 %11, 0
  store i32 %13, ptr %12, align 4
  %14 = getelementptr inbounds %struct.dim3, ptr %4, i32 0, i32 1
  %15 = extractvalue %struct.dim3 %11, 1
  store i32 %15, ptr %14, align 4
  %16 = getelementptr inbounds %struct.dim3, ptr %4, i32 0, i32 2
  %17 = extractvalue %struct.dim3 %11, 2
  store i32 %17, ptr %16, align 4
  %18 = call %struct.dim3 @_ZNK24__cuda_builtin_gridDim_tcv4dim3Ev(ptr noundef nonnull align 1 dereferenceable(1) addrspacecast (ptr addrspace(1) @gridDim to ptr)) #12
  %19 = getelementptr inbounds %struct.dim3, ptr %6, i32 0, i32 0
  %20 = extractvalue %struct.dim3 %18, 0
  store i32 %20, ptr %19, align 4
  %21 = getelementptr inbounds %struct.dim3, ptr %6, i32 0, i32 1
  %22 = extractvalue %struct.dim3 %18, 1
  store i32 %22, ptr %21, align 4
  %23 = getelementptr inbounds %struct.dim3, ptr %6, i32 0, i32 2
  %24 = extractvalue %struct.dim3 %18, 2
  store i32 %24, ptr %23, align 4
  %25 = call noundef i64 @_ZN18cooperative_groups4__v17detailsL14vec3_to_linearIyEET_4dim3S4_(ptr noundef byval(%struct.dim3) align 4 %4, ptr noundef byval(%struct.dim3) align 4 %6) #12
  store i64 %25, ptr %2, align 8
  %26 = load i64, ptr %2, align 8
  %27 = call noundef i32 @_ZN25__cuda_builtin_blockDim_t17__fetch_builtin_xEv() #12
  %28 = call noundef i32 @_ZN25__cuda_builtin_blockDim_t17__fetch_builtin_yEv() #12
  %29 = mul i32 %27, %28
  %30 = call noundef i32 @_ZN25__cuda_builtin_blockDim_t17__fetch_builtin_zEv() #12
  %31 = mul i32 %29, %30
  %32 = zext i32 %31 to i64
  %33 = mul i64 %26, %32
  %34 = call %struct.dim3 @_ZNK26__cuda_builtin_threadIdx_tcv4dim3Ev(ptr noundef nonnull align 1 dereferenceable(1) addrspacecast (ptr addrspace(1) @threadIdx to ptr)) #12
  %35 = getelementptr inbounds %struct.dim3, ptr %8, i32 0, i32 0
  %36 = extractvalue %struct.dim3 %34, 0
  store i32 %36, ptr %35, align 4
  %37 = getelementptr inbounds %struct.dim3, ptr %8, i32 0, i32 1
  %38 = extractvalue %struct.dim3 %34, 1
  store i32 %38, ptr %37, align 4
  %39 = getelementptr inbounds %struct.dim3, ptr %8, i32 0, i32 2
  %40 = extractvalue %struct.dim3 %34, 2
  store i32 %40, ptr %39, align 4
  %41 = call %struct.dim3 @_ZNK25__cuda_builtin_blockDim_tcv4dim3Ev(ptr noundef nonnull align 1 dereferenceable(1) addrspacecast (ptr addrspace(1) @blockDim to ptr)) #12
  %42 = getelementptr inbounds %struct.dim3, ptr %10, i32 0, i32 0
  %43 = extractvalue %struct.dim3 %41, 0
  store i32 %43, ptr %42, align 4
  %44 = getelementptr inbounds %struct.dim3, ptr %10, i32 0, i32 1
  %45 = extractvalue %struct.dim3 %41, 1
  store i32 %45, ptr %44, align 4
  %46 = getelementptr inbounds %struct.dim3, ptr %10, i32 0, i32 2
  %47 = extractvalue %struct.dim3 %41, 2
  store i32 %47, ptr %46, align 4
  %48 = call noundef i32 @_ZN18cooperative_groups4__v17detailsL14vec3_to_linearIjEET_4dim3S4_(ptr noundef byval(%struct.dim3) align 4 %8, ptr noundef byval(%struct.dim3) align 4 %10) #12
  %49 = zext i32 %48 to i64
  %50 = add i64 %33, %49
  ret i64 %50
}

; Function Attrs: alwaysinline convergent mustprogress nounwind
define internal noundef i64 @_ZN18cooperative_groups4__v17detailsL14vec3_to_linearIyEET_4dim3S4_(ptr noundef byval(%struct.dim3) align 4 %0, ptr noundef byval(%struct.dim3) align 4 %1) #1 {
  %3 = getelementptr inbounds %struct.dim3, ptr %0, i32 0, i32 2
  %4 = load i32, ptr %3, align 4
  %5 = zext i32 %4 to i64
  %6 = getelementptr inbounds %struct.dim3, ptr %1, i32 0, i32 1
  %7 = load i32, ptr %6, align 4
  %8 = zext i32 %7 to i64
  %9 = mul i64 %5, %8
  %10 = getelementptr inbounds %struct.dim3, ptr %1, i32 0, i32 0
  %11 = load i32, ptr %10, align 4
  %12 = zext i32 %11 to i64
  %13 = mul i64 %9, %12
  %14 = getelementptr inbounds %struct.dim3, ptr %0, i32 0, i32 1
  %15 = load i32, ptr %14, align 4
  %16 = zext i32 %15 to i64
  %17 = getelementptr inbounds %struct.dim3, ptr %1, i32 0, i32 0
  %18 = load i32, ptr %17, align 4
  %19 = zext i32 %18 to i64
  %20 = mul i64 %16, %19
  %21 = add i64 %13, %20
  %22 = getelementptr inbounds %struct.dim3, ptr %0, i32 0, i32 0
  %23 = load i32, ptr %22, align 4
  %24 = zext i32 %23 to i64
  %25 = add i64 %21, %24
  ret i64 %25
}

; Function Attrs: convergent mustprogress noinline nounwind optnone
define linkonce_odr %struct.dim3 @_ZNK25__cuda_builtin_blockIdx_tcv4dim3Ev(ptr noundef nonnull align 1 dereferenceable(1) %0) #0 comdat align 2 {
  %2 = alloca %struct.dim3, align 4, addrspace(5)
  %3 = addrspacecast ptr addrspace(5) %2 to ptr
  %4 = alloca ptr, align 8, addrspace(5)
  %5 = addrspacecast ptr addrspace(5) %4 to ptr
  store ptr %0, ptr %5, align 8
  %6 = load ptr, ptr %5, align 8
  %7 = call noundef i32 @_ZN25__cuda_builtin_blockIdx_t17__fetch_builtin_xEv() #12
  %8 = call noundef i32 @_ZN25__cuda_builtin_blockIdx_t17__fetch_builtin_yEv() #12
  %9 = call noundef i32 @_ZN25__cuda_builtin_blockIdx_t17__fetch_builtin_zEv() #12
  call void @_ZN4dim3C1Ejjj(ptr noundef nonnull align 4 dereferenceable(12) %3, i32 noundef %7, i32 noundef %8, i32 noundef %9) #12
  %10 = load %struct.dim3, ptr %3, align 4
  ret %struct.dim3 %10
}

; Function Attrs: convergent mustprogress noinline nounwind optnone
define linkonce_odr %struct.dim3 @_ZNK24__cuda_builtin_gridDim_tcv4dim3Ev(ptr noundef nonnull align 1 dereferenceable(1) %0) #0 comdat align 2 {
  %2 = alloca %struct.dim3, align 4, addrspace(5)
  %3 = addrspacecast ptr addrspace(5) %2 to ptr
  %4 = alloca ptr, align 8, addrspace(5)
  %5 = addrspacecast ptr addrspace(5) %4 to ptr
  store ptr %0, ptr %5, align 8
  %6 = load ptr, ptr %5, align 8
  %7 = call noundef i32 @_ZN24__cuda_builtin_gridDim_t17__fetch_builtin_xEv() #12
  %8 = call noundef i32 @_ZN24__cuda_builtin_gridDim_t17__fetch_builtin_yEv() #12
  %9 = call noundef i32 @_ZN24__cuda_builtin_gridDim_t17__fetch_builtin_zEv() #12
  call void @_ZN4dim3C1Ejjj(ptr noundef nonnull align 4 dereferenceable(12) %3, i32 noundef %7, i32 noundef %8, i32 noundef %9) #12
  %10 = load %struct.dim3, ptr %3, align 4
  ret %struct.dim3 %10
}

; Function Attrs: alwaysinline convergent mustprogress nounwind
define linkonce_odr noundef i32 @_ZN25__cuda_builtin_blockIdx_t17__fetch_builtin_yEv() #1 comdat align 2 {
  %1 = call i32 @llvm.amdgcn.workgroup.id.y()
  ret i32 %1
}

; Function Attrs: alwaysinline convergent mustprogress nounwind
define linkonce_odr noundef i32 @_ZN25__cuda_builtin_blockIdx_t17__fetch_builtin_zEv() #1 comdat align 2 {
  %1 = call i32 @llvm.amdgcn.workgroup.id.z()
  ret i32 %1
}

; Function Attrs: nocallback nofree nosync nounwind readnone speculatable willreturn
declare i32 @llvm.nvvm.read.ptx.sreg.ctaid.y() #5

; Function Attrs: nocallback nofree nosync nounwind readnone speculatable willreturn
declare i32 @llvm.nvvm.read.ptx.sreg.ctaid.z() #5

; Function Attrs: alwaysinline convergent mustprogress nounwind
define linkonce_odr noundef i32 @_ZN24__cuda_builtin_gridDim_t17__fetch_builtin_yEv() #1 comdat align 2 {
  %1 = call i32 @cudaamd.nvvm.read.ptx.sreg.nctaid.y()
  ret i32 %1
}

; Function Attrs: alwaysinline convergent mustprogress nounwind
define linkonce_odr noundef i32 @_ZN24__cuda_builtin_gridDim_t17__fetch_builtin_zEv() #1 comdat align 2 {
  %1 = call i32 @cudaamd.nvvm.read.ptx.sreg.nctaid.z()
  ret i32 %1
}

; Function Attrs: nocallback nofree nosync nounwind readnone speculatable willreturn
declare i32 @llvm.nvvm.read.ptx.sreg.nctaid.y() #5

; Function Attrs: nocallback nofree nosync nounwind readnone speculatable willreturn
declare i32 @llvm.nvvm.read.ptx.sreg.nctaid.z() #5

; Function Attrs: alwaysinline convergent mustprogress nounwind
define linkonce_odr void @_ZN18cooperative_groups4__v14syncINS0_15coalesced_groupEEEvRKT_(ptr noundef nonnull align 8 dereferenceable(16) %0) #1 comdat {
  %2 = alloca ptr, align 8, addrspace(5)
  %3 = addrspacecast ptr addrspace(5) %2 to ptr
  store ptr %0, ptr %3, align 8
  %4 = load ptr, ptr %3, align 8
  call void @_ZNK18cooperative_groups4__v115coalesced_group4syncEv(ptr noundef nonnull align 8 dereferenceable(16) %4) #12
  ret void
}

; Function Attrs: alwaysinline convergent mustprogress nounwind
define linkonce_odr void @_ZN18cooperative_groups4__v14syncINS0_12thread_blockEEEvRKT_(ptr noundef nonnull align 8 dereferenceable(16) %0) #1 comdat {
  %2 = alloca ptr, align 8, addrspace(5)
  %3 = addrspacecast ptr addrspace(5) %2 to ptr
  store ptr %0, ptr %3, align 8
  %4 = load ptr, ptr %3, align 8
  call void @_ZN18cooperative_groups4__v112thread_block4syncEv() #12
  ret void
}

; Function Attrs: alwaysinline convergent mustprogress nounwind
define linkonce_odr void @_ZN18cooperative_groups4__v14syncINS0_10grid_groupEEEvRKT_(ptr noundef nonnull align 8 dereferenceable(16) %0) #1 comdat {
  %2 = alloca ptr, align 8, addrspace(5)
  %3 = addrspacecast ptr addrspace(5) %2 to ptr
  store ptr %0, ptr %3, align 8
  %4 = load ptr, ptr %3, align 8
  call void @_ZNK18cooperative_groups4__v110grid_group4syncEv(ptr noundef nonnull align 8 dereferenceable(16) %4) #12
  ret void
}

; Function Attrs: alwaysinline convergent mustprogress nounwind
define linkonce_odr void @_ZNK18cooperative_groups4__v115coalesced_group4syncEv(ptr noundef nonnull align 8 dereferenceable(16) %0) #1 comdat align 2 {
  %2 = alloca ptr, align 8, addrspace(5)
  %3 = addrspacecast ptr addrspace(5) %2 to ptr
  store ptr %0, ptr %3, align 8
  %4 = load ptr, ptr %3, align 8
  %5 = getelementptr inbounds %"class.cooperative_groups::__v1::thread_group", ptr %4, i32 0, i32 0
  %6 = getelementptr inbounds %"struct.cooperative_groups::__v1::thread_group::tg_data", ptr %5, i32 0, i32 1
  %7 = load i32, ptr %6, align 8
  call void @_Z10__syncwarpj(i32 noundef %7) #12
  ret void
}

; Function Attrs: convergent mustprogress noinline nounwind optnone
define linkonce_odr void @_Z10__syncwarpj(i32 noundef %0) #0 comdat {
  %2 = alloca i32, align 4, addrspace(5)
  %3 = addrspacecast ptr addrspace(5) %2 to ptr
  store i32 %0, ptr %3, align 4
  %4 = load i32, ptr %3, align 4
  call void @llvm.nvvm.bar.warp.sync(i32 %4)
  ret void
}

; Function Attrs: convergent nocallback nounwind
declare void @llvm.nvvm.bar.warp.sync(i32) #6

; Function Attrs: alwaysinline convergent mustprogress nounwind
define linkonce_odr void @_ZN18cooperative_groups4__v112thread_block4syncEv() #1 comdat align 2 {
  call void @_ZN18cooperative_groups4__v17details3ctaL4syncEv() #12
  ret void
}

; Function Attrs: alwaysinline convergent mustprogress nounwind
define internal void @_ZN18cooperative_groups4__v17details3ctaL4syncEv() #1 {
  call void @_Z14__barrier_syncj(i32 noundef 0) #12
  ret void
}

; Function Attrs: convergent mustprogress noinline nounwind optnone
define linkonce_odr void @_Z14__barrier_syncj(i32 noundef %0) #0 comdat {
  %2 = alloca i32, align 4, addrspace(5)
  %3 = addrspacecast ptr addrspace(5) %2 to ptr
  store i32 %0, ptr %3, align 4
  %4 = load i32, ptr %3, align 4
  call void @llvm.nvvm.barrier.sync(i32 %4)
  ret void
}

; Function Attrs: convergent nocallback nounwind
declare void @llvm.nvvm.barrier.sync(i32) #6

; Function Attrs: alwaysinline convergent mustprogress nounwind
define linkonce_odr void @_ZNK18cooperative_groups4__v110grid_group4syncEv(ptr noundef nonnull align 8 dereferenceable(16) %0) #1 comdat align 2 {
  %2 = alloca ptr, align 8, addrspace(5)
  %3 = addrspacecast ptr addrspace(5) %2 to ptr
  store ptr %0, ptr %3, align 8
  %4 = load ptr, ptr %3, align 8
  %5 = call noundef zeroext i1 @_ZNK18cooperative_groups4__v110grid_group8is_validEv(ptr noundef nonnull align 8 dereferenceable(16) %4) #12
  br i1 %5, label %7, label %6

6:                                                ; preds = %1
  call void @_ZL6__trapv() #12
  br label %7

7:                                                ; preds = %6, %1
  %8 = getelementptr inbounds %"class.cooperative_groups::__v1::thread_group", ptr %4, i32 0, i32 0
  %9 = getelementptr inbounds %"struct.cooperative_groups::__v1::thread_group::gg_data", ptr %8, i32 0, i32 0
  %10 = load ptr, ptr %9, align 8
  %11 = getelementptr inbounds %"struct.cooperative_groups::__v1::details::grid_workspace", ptr %10, i32 0, i32 1
  call void @_ZN18cooperative_groups4__v17details4gridL4syncEPj(ptr noundef %11) #12
  ret void
}

; Function Attrs: alwaysinline convergent mustprogress nounwind
define linkonce_odr noundef zeroext i1 @_ZNK18cooperative_groups4__v110grid_group8is_validEv(ptr noundef nonnull align 8 dereferenceable(16) %0) #1 comdat align 2 {
  %2 = alloca ptr, align 8, addrspace(5)
  %3 = addrspacecast ptr addrspace(5) %2 to ptr
  store ptr %0, ptr %3, align 8
  %4 = load ptr, ptr %3, align 8
  %5 = getelementptr inbounds %"class.cooperative_groups::__v1::thread_group", ptr %4, i32 0, i32 0
  %6 = getelementptr inbounds %"struct.cooperative_groups::__v1::thread_group::gg_data", ptr %5, i32 0, i32 0
  %7 = load ptr, ptr %6, align 8
  %8 = icmp ne ptr %7, null
  ret i1 %8
}

; Function Attrs: alwaysinline convergent mustprogress nounwind
define internal void @_ZL6__trapv() #1 {
  call void asm sideeffect "trap;", ""() #12, !srcloc !12
  ret void
}

; Function Attrs: alwaysinline convergent mustprogress nounwind
define internal void @_ZN18cooperative_groups4__v17details4gridL4syncEPj(ptr noundef %0) #1 {
  %2 = alloca ptr, align 8, addrspace(5)
  %3 = addrspacecast ptr addrspace(5) %2 to ptr
  %4 = alloca i32, align 4, addrspace(5)
  %5 = addrspacecast ptr addrspace(5) %4 to ptr
  store ptr %0, ptr %3, align 8
  %6 = call noundef i32 @_ZN24__cuda_builtin_gridDim_t17__fetch_builtin_xEv() #12
  %7 = call noundef i32 @_ZN24__cuda_builtin_gridDim_t17__fetch_builtin_yEv() #12
  %8 = mul i32 %6, %7
  %9 = call noundef i32 @_ZN24__cuda_builtin_gridDim_t17__fetch_builtin_zEv() #12
  %10 = mul i32 %8, %9
  store i32 %10, ptr %5, align 4
  %11 = load i32, ptr %5, align 4
  %12 = load ptr, ptr %3, align 8
  call void @_ZN18cooperative_groups4__v17detailsL10sync_gridsEjPVj(i32 noundef %11, ptr noundef %12) #12
  ret void
}

; Function Attrs: alwaysinline convergent mustprogress nounwind
define internal void @_ZN18cooperative_groups4__v17detailsL10sync_gridsEjPVj(i32 noundef %0, ptr noundef %1) #1 {
  %3 = alloca i32, align 4, addrspace(5)
  %4 = addrspacecast ptr addrspace(5) %3 to ptr
  %5 = alloca ptr, align 8, addrspace(5)
  %6 = addrspacecast ptr addrspace(5) %5 to ptr
  %7 = alloca i8, align 1, addrspace(5)
  %8 = addrspacecast ptr addrspace(5) %7 to ptr
  %9 = alloca i8, align 1, addrspace(5)
  %10 = addrspacecast ptr addrspace(5) %9 to ptr
  %11 = alloca i32, align 4, addrspace(5)
  %12 = addrspacecast ptr addrspace(5) %11 to ptr
  %13 = alloca i32, align 4, addrspace(5)
  %14 = addrspacecast ptr addrspace(5) %13 to ptr
  store i32 %0, ptr %4, align 4
  store ptr %1, ptr %6, align 8
  %15 = call noundef i32 @_ZN26__cuda_builtin_threadIdx_t17__fetch_builtin_xEv() #12
  %16 = call noundef i32 @_ZN26__cuda_builtin_threadIdx_t17__fetch_builtin_yEv() #12
  %17 = add i32 %15, %16
  %18 = call noundef i32 @_ZN26__cuda_builtin_threadIdx_t17__fetch_builtin_zEv() #12
  %19 = add i32 %17, %18
  %20 = icmp eq i32 %19, 0
  %21 = zext i1 %20 to i8
  store i8 %21, ptr %8, align 1
  %22 = call noundef i32 @_ZN25__cuda_builtin_blockIdx_t17__fetch_builtin_xEv() #12
  %23 = call noundef i32 @_ZN25__cuda_builtin_blockIdx_t17__fetch_builtin_yEv() #12
  %24 = add i32 %22, %23
  %25 = call noundef i32 @_ZN25__cuda_builtin_blockIdx_t17__fetch_builtin_zEv() #12
  %26 = add i32 %24, %25
  %27 = icmp eq i32 %26, 0
  %28 = zext i1 %27 to i8
  store i8 %28, ptr %10, align 1
  fence syncscope("workgroup") release
  call void @llvm.amdgcn.s.barrier()
  fence syncscope("workgroup") acquire
  %29 = load i8, ptr %8, align 1
  %30 = trunc i8 %29 to i1
  br i1 %30, label %31, label %51

31:                                               ; preds = %2
  store i32 1, ptr %12, align 4
  %32 = load i8, ptr %10, align 1
  %33 = trunc i8 %32 to i1
  br i1 %33, label %34, label %38

34:                                               ; preds = %31
  %35 = load i32, ptr %4, align 4
  %36 = sub i32 %35, 1
  %37 = sub i32 -2147483648, %36
  store i32 %37, ptr %12, align 4
  br label %38

38:                                               ; preds = %34, %31
  call void @_ZL13__threadfencev() #12
  %39 = load ptr, ptr %6, align 8
  %40 = load i32, ptr %12, align 4
  %41 = call noundef i32 @_ZN18cooperative_groups4__v17detailsL10atomic_addEPVjj(ptr noundef %39, i32 noundef %40) #12
  store i32 %41, ptr %14, align 4
  br label %42

42:                                               ; preds = %48, %38
  %43 = load i32, ptr %14, align 4
  %44 = load ptr, ptr %6, align 8
  %45 = load volatile i32, ptr %44, align 4
  %46 = call noundef zeroext i1 @_ZN18cooperative_groups4__v17detailsL15bar_has_flippedEjj(i32 noundef %43, i32 noundef %45) #12
  %47 = xor i1 %46, true
  br i1 %47, label %48, label %49

48:                                               ; preds = %42
  br label %42, !llvm.loop !13

49:                                               ; preds = %42
  %50 = load ptr, ptr %6, align 8
  call void @_ZN18cooperative_groups4__v17detailsL9bar_flushEPVj(ptr noundef %50) #12
  br label %51

51:                                               ; preds = %49, %2
  fence syncscope("workgroup") release
  call void @llvm.amdgcn.s.barrier()
  fence syncscope("workgroup") acquire
  ret void
}

; Function Attrs: convergent nocallback nounwind
declare void @llvm.nvvm.barrier0() #6

; Function Attrs: alwaysinline convergent mustprogress nounwind
define internal void @_ZL13__threadfencev() #1 {
  call void @llvm.nvvm.membar.gl()
  ret void
}

; Function Attrs: alwaysinline convergent mustprogress nounwind
define internal noundef i32 @_ZN18cooperative_groups4__v17detailsL10atomic_addEPVjj(ptr noundef %0, i32 noundef %1) #1 {
  %3 = alloca ptr, align 8, addrspace(5)
  %4 = addrspacecast ptr addrspace(5) %3 to ptr
  %5 = alloca i32, align 4, addrspace(5)
  %6 = addrspacecast ptr addrspace(5) %5 to ptr
  %7 = alloca i32, align 4, addrspace(5)
  %8 = addrspacecast ptr addrspace(5) %7 to ptr
  store ptr %0, ptr %4, align 8
  store i32 %1, ptr %6, align 4
  %9 = load ptr, ptr %4, align 8
  %10 = load i32, ptr %6, align 4
  %11 = call noundef i32 @_ZL9atomicAddPjj(ptr noundef %9, i32 noundef %10) #12
  store i32 %11, ptr %8, align 4
  %12 = load i32, ptr %8, align 4
  ret i32 %12
}

; Function Attrs: alwaysinline convergent mustprogress nounwind
define internal noundef zeroext i1 @_ZN18cooperative_groups4__v17detailsL15bar_has_flippedEjj(i32 noundef %0, i32 noundef %1) #1 {
  %3 = alloca i32, align 4, addrspace(5)
  %4 = addrspacecast ptr addrspace(5) %3 to ptr
  %5 = alloca i32, align 4, addrspace(5)
  %6 = addrspacecast ptr addrspace(5) %5 to ptr
  store i32 %0, ptr %4, align 4
  store i32 %1, ptr %6, align 4
  %7 = load i32, ptr %4, align 4
  %8 = load i32, ptr %6, align 4
  %9 = xor i32 %7, %8
  %10 = and i32 %9, -2147483648
  %11 = icmp ne i32 %10, 0
  ret i1 %11
}

; Function Attrs: alwaysinline convergent mustprogress nounwind
define internal void @_ZN18cooperative_groups4__v17detailsL9bar_flushEPVj(ptr noundef %0) #1 {
  %2 = alloca ptr, align 8, addrspace(5)
  %3 = addrspacecast ptr addrspace(5) %2 to ptr
  store ptr %0, ptr %3, align 8
  call void @_ZL13__threadfencev() #12
  ret void
}

; Function Attrs: nocallback nounwind
declare void @llvm.nvvm.membar.gl() #7

; Function Attrs: convergent mustprogress noinline nounwind optnone
define internal noundef i32 @_ZL9atomicAddPjj(ptr noundef %0, i32 noundef %1) #0 {
  %3 = alloca ptr, align 8, addrspace(5)
  %4 = addrspacecast ptr addrspace(5) %3 to ptr
  %5 = alloca i32, align 4, addrspace(5)
  %6 = addrspacecast ptr addrspace(5) %5 to ptr
  store ptr %0, ptr %4, align 8
  store i32 %1, ptr %6, align 4
  %7 = load ptr, ptr %4, align 8
  %8 = load i32, ptr %6, align 4
  %9 = call noundef i32 @_ZL12__uAtomicAddPjj(ptr noundef %7, i32 noundef %8) #12
  ret i32 %9
}

; Function Attrs: alwaysinline convergent mustprogress nounwind
define internal noundef i32 @_ZL12__uAtomicAddPjj(ptr noundef %0, i32 noundef %1) #1 {
  %3 = alloca ptr, align 8, addrspace(5)
  %4 = addrspacecast ptr addrspace(5) %3 to ptr
  %5 = alloca i32, align 4, addrspace(5)
  %6 = addrspacecast ptr addrspace(5) %5 to ptr
  store ptr %0, ptr %4, align 8
  store i32 %1, ptr %6, align 4
  %7 = load ptr, ptr %4, align 8
  %8 = load i32, ptr %6, align 4
  %9 = atomicrmw add ptr %7, i32 %8 seq_cst, align 4
  ret i32 %9
}

; Function Attrs: alwaysinline convergent nounwind
define linkonce_odr void @_ZN18cooperative_groups4__v112thread_blockC1Ev(ptr noundef nonnull align 8 dereferenceable(16) %0) unnamed_addr #8 comdat align 2 {
  %2 = alloca ptr, align 8, addrspace(5)
  %3 = addrspacecast ptr addrspace(5) %2 to ptr
  store ptr %0, ptr %3, align 8
  %4 = load ptr, ptr %3, align 8
  call void @_ZN18cooperative_groups4__v112thread_blockC2Ev(ptr noundef nonnull align 8 dereferenceable(16) %4) #12
  ret void
}

; Function Attrs: alwaysinline convergent nounwind
define linkonce_odr void @_ZN18cooperative_groups4__v112thread_blockC2Ev(ptr noundef nonnull align 8 dereferenceable(16) %0) unnamed_addr #8 comdat align 2 {
  %2 = alloca ptr, align 8, addrspace(5)
  %3 = addrspacecast ptr addrspace(5) %2 to ptr
  store ptr %0, ptr %3, align 8
  %4 = load ptr, ptr %3, align 8
  call void @_ZN18cooperative_groups4__v117thread_group_baseILj4EEC2Ev(ptr noundef nonnull align 8 dereferenceable(16) %4) #12
  ret void
}

; Function Attrs: alwaysinline convergent nounwind
define linkonce_odr void @_ZN18cooperative_groups4__v117thread_group_baseILj4EEC2Ev(ptr noundef nonnull align 8 dereferenceable(16) %0) unnamed_addr #8 comdat align 2 {
  %2 = alloca ptr, align 8, addrspace(5)
  %3 = addrspacecast ptr addrspace(5) %2 to ptr
  store ptr %0, ptr %3, align 8
  %4 = load ptr, ptr %3, align 8
  call void @_ZN18cooperative_groups4__v112thread_groupC2Ej(ptr noundef nonnull align 8 dereferenceable(16) %4, i32 noundef 4) #12
  ret void
}

; Function Attrs: alwaysinline convergent nounwind
define linkonce_odr void @_ZN18cooperative_groups4__v112thread_groupC2Ej(ptr noundef nonnull align 8 dereferenceable(16) %0, i32 noundef %1) unnamed_addr #8 comdat align 2 {
  %3 = alloca ptr, align 8, addrspace(5)
  %4 = addrspacecast ptr addrspace(5) %3 to ptr
  %5 = alloca i32, align 4, addrspace(5)
  %6 = addrspacecast ptr addrspace(5) %5 to ptr
  store ptr %0, ptr %4, align 8
  store i32 %1, ptr %6, align 4
  %7 = load ptr, ptr %4, align 8
  %8 = getelementptr inbounds %"class.cooperative_groups::__v1::thread_group", ptr %7, i32 0, i32 0
  %9 = load i32, ptr %6, align 4
  %10 = getelementptr inbounds %"class.cooperative_groups::__v1::thread_group", ptr %7, i32 0, i32 0
  %11 = trunc i32 %9 to i8
  %12 = load i8, ptr %10, align 8
  %13 = and i8 %11, 127
  %14 = shl i8 %13, 1
  %15 = and i8 %12, 1
  %16 = or i8 %15, %14
  store i8 %16, ptr %10, align 8
  %17 = getelementptr inbounds %"class.cooperative_groups::__v1::thread_group", ptr %7, i32 0, i32 0
  %18 = load i8, ptr %17, align 8
  %19 = and i8 %18, -2
  %20 = or i8 %19, 0
  store i8 %20, ptr %17, align 8
  ret void
}

; Function Attrs: alwaysinline convergent mustprogress nounwind
define linkonce_odr noundef i32 @_ZN18cooperative_groups4__v110group_sizeINS0_15coalesced_groupEEEDTcldtfp_4sizeEERKT_(ptr noundef nonnull align 8 dereferenceable(16) %0) #1 comdat {
  %2 = alloca ptr, align 8, addrspace(5)
  %3 = addrspacecast ptr addrspace(5) %2 to ptr
  store ptr %0, ptr %3, align 8
  %4 = load ptr, ptr %3, align 8
  %5 = call noundef i32 @_ZNK18cooperative_groups4__v115coalesced_group4sizeEv(ptr noundef nonnull align 8 dereferenceable(16) %4) #12
  ret i32 %5
}

; Function Attrs: alwaysinline convergent mustprogress nounwind
define linkonce_odr noundef i32 @_ZN18cooperative_groups4__v110group_sizeINS0_12thread_blockEEEDTcldtfp_4sizeEERKT_(ptr noundef nonnull align 8 dereferenceable(16) %0) #1 comdat {
  %2 = alloca ptr, align 8, addrspace(5)
  %3 = addrspacecast ptr addrspace(5) %2 to ptr
  store ptr %0, ptr %3, align 8
  %4 = load ptr, ptr %3, align 8
  %5 = call noundef i32 @_ZN18cooperative_groups4__v112thread_block4sizeEv() #12
  ret i32 %5
}

; Function Attrs: alwaysinline convergent mustprogress nounwind
define linkonce_odr noundef i64 @_ZN18cooperative_groups4__v110group_sizeINS0_10grid_groupEEEDTcldtfp_4sizeEERKT_(ptr noundef nonnull align 8 dereferenceable(16) %0) #1 comdat {
  %2 = alloca ptr, align 8, addrspace(5)
  %3 = addrspacecast ptr addrspace(5) %2 to ptr
  store ptr %0, ptr %3, align 8
  %4 = load ptr, ptr %3, align 8
  %5 = call noundef i64 @_ZNK18cooperative_groups4__v110grid_group4sizeEv(ptr noundef nonnull align 8 dereferenceable(16) %4) #12
  ret i64 %5
}

; Function Attrs: alwaysinline convergent mustprogress nounwind
define linkonce_odr noundef i32 @_ZNK18cooperative_groups4__v115coalesced_group4sizeEv(ptr noundef nonnull align 8 dereferenceable(16) %0) #1 comdat align 2 {
  %2 = alloca ptr, align 8, addrspace(5)
  %3 = addrspacecast ptr addrspace(5) %2 to ptr
  store ptr %0, ptr %3, align 8
  %4 = load ptr, ptr %3, align 8
  %5 = getelementptr inbounds %"class.cooperative_groups::__v1::thread_group", ptr %4, i32 0, i32 0
  %6 = load i64, ptr %5, align 8
  %7 = lshr i64 %6, 8
  %8 = and i64 %7, 16777215
  %9 = trunc i64 %8 to i32
  ret i32 %9
}

; Function Attrs: alwaysinline convergent mustprogress nounwind
define linkonce_odr noundef i32 @_ZN18cooperative_groups4__v112thread_block4sizeEv() #1 comdat align 2 {
  %1 = call noundef i32 @_ZN18cooperative_groups4__v17details3ctaL4sizeEv() #12
  ret i32 %1
}

; Function Attrs: alwaysinline convergent mustprogress nounwind
define internal noundef i32 @_ZN18cooperative_groups4__v17details3ctaL4sizeEv() #1 {
  %1 = call noundef i32 @_ZN25__cuda_builtin_blockDim_t17__fetch_builtin_xEv() #12
  %2 = call noundef i32 @_ZN25__cuda_builtin_blockDim_t17__fetch_builtin_yEv() #12
  %3 = mul i32 %1, %2
  %4 = call noundef i32 @_ZN25__cuda_builtin_blockDim_t17__fetch_builtin_zEv() #12
  %5 = mul i32 %3, %4
  ret i32 %5
}

; Function Attrs: alwaysinline convergent mustprogress nounwind
define linkonce_odr noundef i64 @_ZNK18cooperative_groups4__v110grid_group4sizeEv(ptr noundef nonnull align 8 dereferenceable(16) %0) #1 comdat align 2 {
  %2 = alloca ptr, align 8, addrspace(5)
  %3 = addrspacecast ptr addrspace(5) %2 to ptr
  store ptr %0, ptr %3, align 8
  %4 = load ptr, ptr %3, align 8
  %5 = call noundef i64 @_ZN18cooperative_groups4__v17details4gridL4sizeEv() #12
  ret i64 %5
}

; Function Attrs: alwaysinline convergent mustprogress nounwind
define internal noundef i64 @_ZN18cooperative_groups4__v17details4gridL4sizeEv() #1 {
  %1 = call noundef i32 @_ZN25__cuda_builtin_blockDim_t17__fetch_builtin_zEv() #12
  %2 = call noundef i32 @_ZN24__cuda_builtin_gridDim_t17__fetch_builtin_zEv() #12
  %3 = mul i32 %1, %2
  %4 = zext i32 %3 to i64
  %5 = call noundef i32 @_ZN25__cuda_builtin_blockDim_t17__fetch_builtin_yEv() #12
  %6 = call noundef i32 @_ZN24__cuda_builtin_gridDim_t17__fetch_builtin_yEv() #12
  %7 = mul i32 %5, %6
  %8 = zext i32 %7 to i64
  %9 = mul i64 %4, %8
  %10 = call noundef i32 @_ZN25__cuda_builtin_blockDim_t17__fetch_builtin_xEv() #12
  %11 = zext i32 %10 to i64
  %12 = call noundef i32 @_ZN24__cuda_builtin_gridDim_t17__fetch_builtin_xEv() #12
  %13 = zext i32 %12 to i64
  %14 = mul i64 %11, %13
  %15 = mul i64 %9, %14
  ret i64 %15
}

; Function Attrs: nocallback nofree nosync nounwind readnone speculatable willreturn
declare i32 @llvm.nvvm.read.ptx.sreg.ctaid.x() #5

; Function Attrs: nocallback nofree nosync nounwind readnone speculatable willreturn
declare i32 @llvm.nvvm.read.ptx.sreg.ntid.x() #5

; Function Attrs: nocallback nofree nosync nounwind readnone speculatable willreturn
declare i32 @llvm.nvvm.read.ptx.sreg.tid.x() #5

; Function Attrs: nocallback nofree nosync nounwind readnone speculatable willreturn
declare i32 @llvm.nvvm.read.ptx.sreg.nctaid.x() #5

; Function Attrs: alwaysinline convergent mustprogress nounwind
define internal noundef i32 @_ZL12__iAtomicAddPii(ptr noundef %0, i32 noundef %1) #1 {
  %3 = alloca ptr, align 8, addrspace(5)
  %4 = addrspacecast ptr addrspace(5) %3 to ptr
  %5 = alloca i32, align 4, addrspace(5)
  %6 = addrspacecast ptr addrspace(5) %5 to ptr
  store ptr %0, ptr %4, align 8
  store i32 %1, ptr %6, align 4
  %7 = load ptr, ptr %4, align 8
  %8 = load i32, ptr %6, align 4
  %9 = atomicrmw add ptr %7, i32 %8 seq_cst, align 4
  ret i32 %9
}

; Function Attrs: alwaysinline convergent nounwind
declare dso_local i32 @__nv_popc(i32) #9

; Function Attrs: nocallback nofree nosync nounwind readnone speculatable willreturn
declare i32 @llvm.ctpop.i32(i32) #5

; Function Attrs: nounwind readnone speculatable willreturn
declare i32 @llvm.amdgcn.workgroup.id.x() #10

declare i32 @cudaamd.nvvm.read.ptx.sreg.ntid.x()

; Function Attrs: nounwind readnone speculatable willreturn
declare i32 @llvm.amdgcn.workitem.id.x() #10

declare i32 @cudaamd.nvvm.read.ptx.sreg.nctaid.x()

; Function Attrs: nounwind readnone speculatable willreturn
declare i32 @llvm.amdgcn.workitem.id.y() #10

; Function Attrs: nounwind readnone speculatable willreturn
declare i32 @llvm.amdgcn.workitem.id.z() #10

declare i32 @cudaamd.nvvm.read.ptx.sreg.ntid.y()

declare i32 @cudaamd.nvvm.read.ptx.sreg.ntid.z()

; Function Attrs: nounwind readnone speculatable willreturn
declare i32 @llvm.amdgcn.workgroup.id.y() #10

; Function Attrs: nounwind readnone speculatable willreturn
declare i32 @llvm.amdgcn.workgroup.id.z() #10

declare i32 @cudaamd.nvvm.read.ptx.sreg.nctaid.y()

declare i32 @cudaamd.nvvm.read.ptx.sreg.nctaid.z()

; Function Attrs: convergent nounwind willreturn
declare void @llvm.amdgcn.s.barrier() #11

declare i32 @_Z9atomicAddPjj(ptr, i32)

declare i32 @_Z9atomicAddPii(ptr, i32)

declare i64 @_Z9atomicAddPyy(ptr, i64)

declare float @_Z9atomicAddPff(ptr, float)

declare i32 @_Z8atomicOrPii(ptr, i32)

declare i32 @_Z8atomicOrPjj(ptr, i32)

declare i64 @_Z8atomicOrPyy(ptr, i64)

declare i32 @_Z9atomicAndPii(ptr, i32)

declare i32 @_Z9atomicAndPjj(ptr, i32)

declare i64 @_Z9atomicAndPyy(ptr, i64)

declare i32 @_Z10atomicExchPii(ptr, i32)

declare i32 @_Z10atomicExchPjj(ptr, i32)

declare i64 @_Z10atomicExchPyy(ptr, i64)

declare float @_Z10atomicExchPff(ptr, float)

declare i32 @_Z9atomicDecPjj(ptr, i32)

declare i32 @_Z9atomicIncPjj(ptr, i32)

declare i32 @_Z9atomicMaxPii(ptr, i32)

declare i32 @_Z9atomicMaxPjj(ptr, i32)

declare i64 @_Z9atomicMaxPyy(ptr, i64)

declare i32 @_Z9atomicMinPii(ptr, i32)

declare i32 @_Z9atomicMinPjj(ptr, i32)

declare i64 @_Z9atomicMinPyy(ptr, i64)

declare i32 @_Z9atomicSubPii(ptr, i32)

declare i32 @_Z9atomicSubPjj(ptr, i32)

declare i32 @_Z9atomicXorPii(ptr, i32)

declare i32 @_Z9atomicXorPjj(ptr, i32)

declare i64 @_Z9atomicXorPyy(ptr, i64)

declare i32 @_Z9atomicCASPiii(ptr, i32, i32)

declare i32 @_Z9atomicCASPjjj(ptr, i32, i32)

declare i64 @_Z9atomicCASPyyy(ptr, i64, i64)

attributes #0 = { convergent mustprogress noinline nounwind optnone "frame-pointer"="all" "min-legal-vector-width"="0" "no-trapping-math"="true" "stack-protector-buffer-size"="8" }
attributes #1 = { alwaysinline convergent mustprogress nounwind "frame-pointer"="all" "min-legal-vector-width"="0" "no-trapping-math"="true" "stack-protector-buffer-size"="8" }
attributes #2 = { argmemonly nocallback nofree nounwind willreturn }
attributes #3 = { convergent mustprogress noinline norecurse nounwind optnone "frame-pointer"="all" "min-legal-vector-width"="0" "no-trapping-math"="true" "stack-protector-buffer-size"="8" }
attributes #4 = { convergent noinline nounwind optnone "frame-pointer"="all" "min-legal-vector-width"="0" "no-trapping-math"="true" "stack-protector-buffer-size"="8" }
attributes #5 = { nocallback nofree nosync nounwind readnone speculatable willreturn }
attributes #6 = { convergent nocallback nounwind }
attributes #7 = { nocallback nounwind }
attributes #8 = { alwaysinline convergent nounwind "frame-pointer"="all" "min-legal-vector-width"="0" "no-trapping-math"="true" "stack-protector-buffer-size"="8" }
attributes #9 = { alwaysinline convergent nounwind "disable-tail-calls"="false" "frame-pointer"="all" "less-precise-fpmad"="false" "no-infs-fp-math"="false" "no-nans-fp-math"="false" "no-trapping-math"="true" "stack-protector-buffer-size"="8" "unsafe-fp-math"="false" "use-soft-float"="false" }
attributes #10 = { nounwind readnone speculatable willreturn }
attributes #11 = { convergent nounwind willreturn }
attributes #12 = { convergent nounwind }

!llvm.module.flags = !{!0, !1, !2, !3, !4}
!nvvm.annotations = !{!5}
!llvm.ident = !{!6, !7}

!0 = !{i32 2, !"SDK Version", [2 x i32] [i32 11, i32 5]}
!1 = !{i32 1, !"wchar_size", i32 4}
!2 = !{i32 4, !"nvvm-reflect-ftz", i32 0}
!3 = !{i32 7, !"PIC Level", i32 2}
!4 = !{i32 7, !"frame-pointer", i32 2}
!5 = !{ptr @_Z16sum_kernel_blockPiS_i, !"kernel", i32 1}
!6 = !{!"clang version 16.0.0 (https://github.com/llvm/llvm-project 809855b56f06dd7182685f88fbbc64111df9339a)"}
!7 = !{!"clang version 3.8.0 (tags/RELEASE_380/final)"}
!8 = distinct !{!8, !9}
!9 = !{!"llvm.loop.mustprogress"}
!10 = distinct !{!10, !9}
!11 = !{i64 942907}
!12 = !{i64 542766}
!13 = distinct !{!13, !9}
